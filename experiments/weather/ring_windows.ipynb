{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7384006f-a3fc-4501-820d-b3852f4e3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] Connection to localhost:5431\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import torch\n",
    "\n",
    "from lib.train_dataclasses import TrainConfig\n",
    "from lib.train_dataclasses import TrainRun\n",
    "from lib.train_dataclasses import OptimizerConfig\n",
    "from lib.train_dataclasses import ComputeConfig\n",
    "\n",
    "from lib.classification_metrics import create_classification_metrics\n",
    "from lib.data_registry import DataSpiralsConfig\n",
    "from lib.datasets.spiral_visualization import visualize_spiral\n",
    "from lib.models.mlp import MLPClassConfig\n",
    "from lib.generic_ablation import generic_ablation\n",
    "\n",
    "from lib.distributed_trainer import distributed_train\n",
    "from lib.ddp import ddp_setup\n",
    "from lib.files import prepare_results\n",
    "from lib.render_psql import setup_psql, add_artifact, add_train_run\n",
    "\n",
    "\n",
    "def create_config(mlp_dim, ensemble_id):\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def ce_loss(output, batch):\n",
    "        return loss(output[\"logits\"], batch[\"target\"])\n",
    "\n",
    "    train_config = TrainConfig(\n",
    "        model_config=MLPClassConfig(widths=[mlp_dim, mlp_dim]),\n",
    "        train_data_config=DataSpiralsConfig(seed=0, N=1000),\n",
    "        val_data_config=DataSpiralsConfig(seed=1, N=500),\n",
    "        loss=ce_loss,\n",
    "        optimizer=OptimizerConfig(\n",
    "            optimizer=torch.optim.Adam, kwargs=dict(weight_decay=0.0001)\n",
    "        ),\n",
    "        batch_size=500,\n",
    "        ensemble_id=ensemble_id,\n",
    "    )\n",
    "    train_eval = create_classification_metrics(visualize_spiral, 2)\n",
    "    train_run = TrainRun(\n",
    "        compute_config=ComputeConfig(distributed=False, num_workers=1),\n",
    "        train_config=train_config,\n",
    "        train_eval=train_eval,\n",
    "        epochs=1,\n",
    "        save_nth_epoch=20,\n",
    "        validate_nth_epoch=20,\n",
    "        notes=dict(purpose=\"isolatitude window\")\n",
    "    )\n",
    "    return train_run\n",
    "\n",
    "\n",
    "config = create_config(100, 0)\n",
    "add_train_run(config)\n",
    "result_path = prepare_results(\"ring_windows\", config)\n",
    "setup_psql()\n",
    "    #add_artifact(configs[0], \"plot.png\", path / \"plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d3ed22-3bb8-41bf-999e-855dccbbd975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import healpix\n",
    "import chealpix as chp\n",
    "import numpy as np\n",
    "\n",
    "NSIDE = 4\n",
    "n_pixels = healpix.nside2npix(NSIDE)\n",
    "n_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284732c2-f52d-4925-958a-d3b45bab6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = np.zeros((n_pixels,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6a3f80-e281-4a00-b0c7-bad6f7bdf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_idx = list(range(0, NSIDE))\n",
    "current_idx = 0\n",
    "north_idxs = []\n",
    "north_eq_idxs = []\n",
    "south_eq_idxs = []\n",
    "south_idxs = []\n",
    "for window_idx in polar_idx:\n",
    "    north_idxs.append([ current_idx + i for i in range(4 * (window_idx + 1))])\n",
    "    current_idx += 4 * (window_idx + 1)\n",
    "\n",
    "for window_idx in range(NSIDE):\n",
    "    north_eq_idxs.append([current_idx + i for i in range(4*NSIDE)])\n",
    "    current_idx += 4*NSIDE\n",
    "\n",
    "for window_idx in range(NSIDE - 1):\n",
    "    south_eq_idxs.append([current_idx + i for i in range(4*NSIDE)])\n",
    "    current_idx += 4*NSIDE\n",
    "\n",
    "# nside 2, 0 -> 0\n",
    "\n",
    "# nside 3, 0 -> 1\n",
    "# nside 3, 1 -> 0\n",
    "for window in reversed(north_idxs):\n",
    "    south_idxs.append([n_pixels - 1 - idx for idx in window])\n",
    "#for window_idx in polar_idx:\n",
    "#    south_idxs.append([ current_idx + i for i in range(4 * ((NSIDE - 1 - window_idx) + 1))])\n",
    "#    current_idx += 4 * ((NSIDE - 1 - window_idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc9343e8-c1d3-4071-96e1-0573e9ae202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3],\n",
       " [4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
       " [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6acdc006-7178-464a-90ca-f551a2db1b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(north_eq_idxs + south_eq_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb79ee2-3213-4103-984e-ee4eae0cf2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[167,\n",
       "  166,\n",
       "  165,\n",
       "  164,\n",
       "  163,\n",
       "  162,\n",
       "  161,\n",
       "  160,\n",
       "  159,\n",
       "  158,\n",
       "  157,\n",
       "  156,\n",
       "  155,\n",
       "  154,\n",
       "  153,\n",
       "  152],\n",
       " [179, 178, 177, 176, 175, 174, 173, 172, 171, 170, 169, 168],\n",
       " [187, 186, 185, 184, 183, 182, 181, 180],\n",
       " [191, 190, 189, 188]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "south_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e179ea45-b0c9-498f-a5e9-012614cce159",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_windows = north_idxs + north_eq_idxs + south_eq_idxs + south_idxs\n",
    "colors = np.arange(len(all_windows))\n",
    "np.random.shuffle(colors)\n",
    "for idx, window in enumerate(all_windows):\n",
    "    n_pixels_in_window = len(window)\n",
    "    n_sub_windows = n_pixels_in_window // 16 + 1\n",
    "    nest_idxs = chp.ring2nest(NSIDE, window)\n",
    "    for sub_idx in range(n_sub_windows):\n",
    "        sub_idxs = nest_idxs[sub_idx::n_sub_windows]\n",
    "        #print(sub_idxs.shape)\n",
    "        hp[sub_idxs] =  float(colors[(sub_idx + idx) % len(all_windows)])#float(2*idx % len(all_windows)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3302adb-1ec1-4eb0-a378-aca00380c7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 14.,  5.,  6., 14.,  6.,  7.,  8., 14.,  6.,  7.,  8.,  8.,\n",
       "       12., 12.,  1.,  5., 14.,  5.,  6., 14.,  6.,  7.,  8., 14.,  6.,\n",
       "        7.,  8.,  8., 12., 12.,  1.,  5., 14.,  5.,  6., 14.,  6.,  7.,\n",
       "        8., 14.,  6.,  7.,  8.,  8., 12., 12.,  1.,  5., 14.,  5.,  6.,\n",
       "       14.,  6.,  7.,  8., 14.,  6.,  7.,  8.,  8., 12., 12.,  1., 10.,\n",
       "        2., 10.,  3.,  2.,  3.,  4.,  4.,  2.,  3.,  4.,  4.,  5., 14.,\n",
       "        5.,  6., 10.,  2., 10.,  3.,  2.,  3.,  4.,  4.,  2.,  3.,  4.,\n",
       "        4.,  5., 14.,  5.,  6., 10.,  2., 10.,  3.,  2.,  3.,  4.,  4.,\n",
       "        2.,  3.,  4.,  4.,  5., 14.,  5.,  6., 10.,  2., 10.,  3.,  2.,\n",
       "        3.,  4.,  4.,  2.,  3.,  4.,  4.,  5., 14.,  5.,  6.,  9.,  0.,\n",
       "        0., 13., 13., 11., 13., 11., 13., 11., 13., 11., 10.,  2., 10.,\n",
       "        3.,  9.,  0.,  0., 13., 13., 11., 13., 11., 13., 11., 13., 11.,\n",
       "       10.,  2., 10.,  3.,  9.,  0.,  0., 13., 13., 11., 13., 11., 13.,\n",
       "       11., 13., 11., 10.,  2., 10.,  3.,  9.,  0.,  0., 13., 13., 11.,\n",
       "       13., 11., 13., 11., 13., 11., 10.,  2., 10.,  3.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb269bd-e454-418d-a466-f6c22e0d5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_register(name, array):\n",
    "    path = result_path / f\"{name}.npy\"\n",
    "\n",
    "    np.save(\n",
    "        path,\n",
    "        array[None, :],\n",
    "    )\n",
    "    add_artifact(config, name, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "222413ac-d4d1-46a0-851e-6796f22eee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] Connection to alvis2:5431\n",
      "[db] Uploading artifact\n",
      "[db] Chunk 1\n",
      "[Database] Added artifact window_nside_1.npy: /mimer/NOBACKUP/groups/naiss2023-6-319/eqp/artifacts/results/ring_windows_git_ea96398_config_53db940/window_nside_1.npy.npy\n"
     ]
    }
   ],
   "source": [
    "save_and_register(f\"window_nside_{NSIDE}.npy\", hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e18f5b-393c-4fe2-a036-d5853b0d2951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0a1257-ae87-485f-a804-db79ce5dcbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_windows = north_idxs + north_eq_idxs + south_eq_idxs + south_idxs\n",
    "4 * 256 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a926c83e-2531-48d4-b163-d4775e486c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([4, 8, 12, 16, 16, 16, 16, 16, 16, 16, 16, 16, 12, 8, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b40e0-28b5-4051-84bf-776e608dc3a5",
   "metadata": {},
   "source": [
    "# With depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2980c220-0488-44db-b97d-c6b0f8aa0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpix\n",
    "import chealpix as chp\n",
    "\n",
    "def get_isolatitude_windows_hp(nside):\n",
    "    polar_idx = list(range(0, nside))\n",
    "    current_idx = 0\n",
    "    north_idxs = []\n",
    "    north_eq_idxs = []\n",
    "    south_eq_idxs = []\n",
    "    south_idxs = []\n",
    "    n_pixels = healpix.nside2npix(nside)\n",
    "    for window_idx in polar_idx:\n",
    "        north_idxs.append([ current_idx + i for i in range(4 * (window_idx + 1))])\n",
    "        current_idx += 4 * (window_idx + 1)\n",
    "    \n",
    "    for window_idx in range(nside):\n",
    "        north_eq_idxs.append([current_idx + i for i in range(4*nside)])\n",
    "        current_idx += 4*nside\n",
    "    \n",
    "    for window_idx in range(nside - 1):\n",
    "        south_eq_idxs.append([current_idx + i for i in range(4*nside)])\n",
    "        current_idx += 4*nside\n",
    "    \n",
    "    # nside 2, 0 -> 0\n",
    "    \n",
    "    # nside 3, 0 -> 1\n",
    "    # nside 3, 1 -> 0\n",
    "    for window in reversed(north_idxs):\n",
    "        south_idxs.append([n_pixels - 1 - idx for idx in window])\n",
    "\n",
    "    return north_idxs + north_eq_idxs + south_eq_idxs + south_idxs\n",
    "\n",
    "def to_interspersed_windows(nside, max_size, window):\n",
    "    n_pixels_in_window = len(window)\n",
    "    n_sub_windows = n_pixels_in_window // max_size + 1\n",
    "    nest_idxs = chp.ring2nest(nside, window)\n",
    "    sub_windows = []\n",
    "    for sub_idx in range(n_sub_windows):\n",
    "        sub_windows.append(nest_idxs[sub_idx::n_sub_windows].tolist())\n",
    "    return sub_windows\n",
    "\n",
    "def flattened_interspersed(nside, max_window_size, windows):\n",
    "    interspersed = [to_interspersed_windows(nside, max_window_size, window) for window in windows]\n",
    "    return [ window for subwins in interspersed for window in subwins ]\n",
    "\n",
    "def pad_windows(max_window_size, windows):\n",
    "    padded_windows = []\n",
    "    current_padded = []\n",
    "    for idx, window in enumerate(windows):\n",
    "        fits_in_window = len(current_padded) + len(window) <= max_window_size\n",
    "        if fits_in_window:\n",
    "            current_padded.extend(window)\n",
    "        if not fits_in_window:\n",
    "            current_padded.extend([current_padded[-1]] * (max_window_size - len(current_padded)))\n",
    "            padded_windows.append(current_padded)\n",
    "            current_padded = list(window)\n",
    "        if idx == len(windows) - 1 and len(current_padded) > 0:\n",
    "            current_padded.extend([current_padded[-1]] * (max_window_size - len(current_padded)))\n",
    "            padded_windows.append(current_padded)\n",
    "    return padded_windows\n",
    "\n",
    "def test_pad_windows(nside):\n",
    "    max_window_size = 16\n",
    "    hp_windows = get_isolatitude_windows_hp(nside)\n",
    "    interspersed = flattened_interspersed(nside, max_window_size, hp_windows)\n",
    "    padded_windows = pad_windows(max_window_size, interspersed)\n",
    "    \n",
    "    data = torch.rand((2, 3, healpix.nside2npix(nside), 48))\n",
    "    data_pre = data.clone()\n",
    "    indices = torch.tensor(padded_windows)\n",
    "\n",
    "    # Extract windows\n",
    "    windowed = data[:, :, indices, :]\n",
    "\n",
    "    # Use windows to reconstruct original tensor\n",
    "    new = torch.zeros(data.shape)\n",
    "    new[:, :, indices, :] = windowed\n",
    "    assert (new - data_pre).sum() == 0.0\n",
    "\n",
    "def window_reverse(windows, window_size, D, N):\n",
    "    window_size_d, window_size_hp = window_size\n",
    "    nside = healpix.npix2nside(N)\n",
    "\n",
    "    hp_windows = get_isolatitude_windows_hp(nside)\n",
    "    interspersed = flattened_interspersed(nside, window_size_hp, hp_windows)\n",
    "    padded_windows = pad_windows(window_size_hp, interspersed)\n",
    "\n",
    "    indices = torch.tensor(padded_windows)    \n",
    "    \n",
    "    Nw, W = indices.shape\n",
    "\n",
    "    B = int(windows.shape[0] / (D * N // (window_size_hp * window_size_d)))\n",
    "    x = windows.view(\n",
    "        B, D // window_size_d, Nw, window_size_d, W, -1\n",
    "    )\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "    \n",
    "    # B, Nd, Wd, Nw, W, C\n",
    "    # 0   1   2   3  4  5\n",
    "    x = x.contiguous().view(B, D, Nw, W, C)\n",
    "    \n",
    "    new = torch.zeros(data.shape)\n",
    "    new[:, :, indices, :] = x\n",
    "\n",
    "    return new\n",
    "\n",
    "def window_partition(x: torch.Tensor, window_size):\n",
    "    window_size_d, window_size_hp = window_size\n",
    "    \n",
    "    nside = healpix.npix2nside(x.shape[2])\n",
    "    hp_windows = get_isolatitude_windows_hp(nside)\n",
    "    interspersed = flattened_interspersed(nside, window_size_hp, hp_windows)\n",
    "    padded_windows = pad_windows(window_size_hp, interspersed)\n",
    "\n",
    "    indices = torch.tensor(padded_windows)    \n",
    "    windowed = data[:, :, indices, :]\n",
    "\n",
    "    B, D, Nw, W, C = windowed.shape\n",
    "    x = windowed.view(B, D // window_size_d, window_size_d, Nw, W, C)\n",
    "    \n",
    "    # B, Nd, Wd, Nw, W, C\n",
    "    # 0   1   2   3  4  5\n",
    "    \n",
    "    x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "    windows = x.contiguous().view(-1, window_size_d * window_size_hp, C)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33573f8e-0e80-4bdd-a044-8cb3fc6d153a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d2a26b55-1361-43be-8d80-401061ac2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition_nest(x: torch.Tensor, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, D, N, C)\n",
    "        window_size (int,int): Must be a power of 2 in the healpy grid.\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size_d * window_size_hp , C)\n",
    "    \"\"\"\n",
    "    # assert that window_size is a power of 2\n",
    "    # assert (math.log(window_size) / math.log(2)) % 1 == 0\n",
    "\n",
    "    B, D, N, C = x.shape\n",
    "    window_size_d, window_size_hp = window_size\n",
    "    x = x.view(\n",
    "        B, D // window_size_d, window_size_d, N // window_size_hp, window_size_hp, C\n",
    "    )\n",
    "    # B, D//wd, wd, N//whp, whp, c\n",
    "    # 0  1      2   3       4    5\n",
    "    # =>\n",
    "    # B, D//wd, N//whp, wd, whp, c\n",
    "    # 0  1      3       2   4    5\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "    windows = x.contiguous().view(-1, window_size_d * window_size_hp, C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse_nest(windows, window_size, D, N):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, C)\n",
    "        window_size (int): Must be a power of 2 in the healpy grid\n",
    "        N (int): Number of pixels in the healpy grid\n",
    "\n",
    "    Returns:\n",
    "        x: (B, N, C)\n",
    "    \"\"\"\n",
    "    # assert that window_size is a power of 2\n",
    "    # assert (math.log(window_size) / math.log(2)) % 1 == 0\n",
    "    window_size_d, window_size_hp = window_size\n",
    "\n",
    "    B = int(windows.shape[0] / (D * N // (window_size_hp * window_size_d)))\n",
    "    x = windows.view(\n",
    "        B, D // window_size_d, N // window_size_hp, window_size_d, window_size_hp, -1\n",
    "    )\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "    x = x.contiguous().view(B, D, N, -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e300037b-d3bf-4cda-ab11-e9150e6f416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pad_windows(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "613fb4aa-d028-4ccd-addf-e5dfc1ce0865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand((2, 8, healpix.nside2npix(256), 48))\n",
    "windows = window_partition(data, (2, 64))\n",
    "post = window_reverse(windows, (2, 64), 8, healpix.nside2npix(256))\n",
    "(post - data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "47e683f8-4b1b-434e-b83d-2e04e7725178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 192, 48])\n",
      "192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(healpix.nside2npix(4))\n",
    "#nside = healpix.npix2nside(data.shape[2])\n",
    "nside = 4\n",
    "window_size_hp = 16\n",
    "window_size_d = 2\n",
    "hp_windows = get_isolatitude_windows_hp(nside)\n",
    "interspersed = flattened_interspersed(nside, window_size_hp, hp_windows)\n",
    "padded_windows = pad_windows(window_size_hp, interspersed)\n",
    "\n",
    "\n",
    "data = torch.rand((2, 8, healpix.nside2npix(4), 48))\n",
    "\n",
    "N = healpix.nside2npix(4)\n",
    "\n",
    "data_pre = data.clone()\n",
    "indices = torch.tensor(padded_windows)\n",
    "#indices = indices.unsqueeze(0).unsqueeze(0)\n",
    "windowed = data[:, :, indices, :]\n",
    "\n",
    "B, D, Nw, W, C = windowed.shape\n",
    "x = windowed.view(B, D // window_size_d, window_size_d, Nw, W, C)\n",
    "\n",
    "# B, Nd, Wd, Nw, W, C\n",
    "# 0   1   2   3  4  5\n",
    "\n",
    "x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "windows = x.contiguous().view(-1, window_size_d * window_size_hp, C)\n",
    "windows.shape\n",
    "\n",
    "\n",
    "B = int(windows.shape[0] / (D * N // (window_size_hp * window_size_d)))\n",
    "x = windows.view(\n",
    "    B, D // window_size_d, Nw, window_size_d, W, -1\n",
    ")\n",
    "x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "\n",
    "# B, Nd, Wd, Nw, W, C\n",
    "# 0   1   2   3  4  5\n",
    "x = x.contiguous().view(B, D, Nw, W, C)\n",
    "\n",
    "new = torch.zeros(data.shape)\n",
    "new[:, :, indices, :] = x\n",
    "\n",
    "(new - data_pre).sum()\n",
    "#x = x.contiguous().view(B, D, N, -1)\n",
    "\n",
    "#hp_windows[:20]\n",
    "#padded_windows[:5]\n",
    "#print(indices.shape)\n",
    "#for hp_window in padded_windows:\n",
    "#    tindex = torch.tensor(hp_window)\n",
    "#    window = torch.index_select(data, 2, tindex)\n",
    "#    data[:, :, tindex, :] = window\n",
    "\n",
    "#(data_pre - data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1df593-6a36-4bfa-8df1-76e9cfdad2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50907d7-3415-48b0-bea7-caf856460d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848ec82-788e-4186-8d60-5ffdb35c8725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b0c1b-3bcb-4e31-b1c6-2afc961411b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7d188-99c8-4382-82bf-5f89f6de65bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "79758edc-b2b7-4ebb-a3cb-a9e9ac83e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 13, 16, 48])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3f2aca14-fd2d-45be-9a89-97bea51bd4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 16])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554cb7f0-c0b6-4350-9449-1cbf233bf95f",
   "metadata": {},
   "source": [
    "# Data tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9f9d86-026c-4b26-acb8-7793356a4265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with batch size 8\n",
      "1 samples in 2.20s, 0 left\n",
      "\u001b[92m[Compute environment] paths: \n",
      "\u001b[92m[Paths] checkpoints: checkpoints (/Users/hampus/projects/equivariant-posteriors/experiments/weather/checkpoints)\u001b[0m\n",
      "\u001b[92m[Paths] locks: locks (/Users/hampus/projects/equivariant-posteriors/experiments/weather/locks)\u001b[0m\n",
      "\u001b[92m[Paths] distributed_requests: distributed_requests (/Users/hampus/projects/equivariant-posteriors/experiments/weather/distributed_requests)\u001b[0m\n",
      "\u001b[92m[Paths] artifacts: artifacts (/Users/hampus/projects/equivariant-posteriors/experiments/weather/artifacts)\u001b[0m\n",
      "\u001b[92m[Paths] datasets: datasets (/Users/hampus/projects/equivariant-posteriors/experiments/weather/datasets)\u001b[0m\u001b[0m\n",
      "\u001b[92m[Compute environment] postgres_host: localhost\u001b[0m\n",
      "\u001b[92m[Compute environment] postgres_port: 5431\u001b[0m\n",
      "\u001b[92m[Compute environment] postgres_password: herdeherde\u001b[0m\n",
      "Saved npy datasets/driscoll_healy_False_end_year_2017_nside_64_start_year_2007_version_10.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import experiments.weather.models.swin_hp_pangu as shp\n",
    "import lib.data_factory as data_factory\n",
    "import experiments.weather.persisted_configs.train_nside64 as c\n",
    "import experiments.weather.models.swin_hp_pangu as shp\n",
    "import torch\n",
    "import experiments.weather.data as data\n",
    "\n",
    "\n",
    "df = data_factory.get_factory()\n",
    "config = c.create_config(0)\n",
    "\n",
    "data.serialize_dataset_statistics(config.train_config.model_config.nside, test_with_one_sample=True)\n",
    "ds = df.create(config.train_config.train_data_config)\n",
    "pe = shp.PatchEmbed(config.train_config.model_config, ds.__class__.data_spec(config.train_config.train_data_config))\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=1)\n",
    "batch = next(iter(dl))\n",
    "surface = batch[\"input_surface\"]\n",
    "upper = batch[\"input_upper\"]\n",
    "data = pe(surface, upper)\n",
    "config.train_config.model_config.nside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215ec47d-c057-4992-b31b-80d6987873b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 49152, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = surface.unsqueeze(1).permute(0, 1, 3, 2)\n",
    "test = torch.concat([test, test], dim=1)\n",
    "N = test.shape[-2]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b0a22-9c0c-4748-812d-9f7f187eca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5010fdf0-9784-4558-8050-e14f9c1809ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments.weather.models.hp_windowing_isolatitude as win\n",
    "import experiments.weather.models.hp_shifting as shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7480d-ad66-4fd3-b812-e80218649d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad7c21-eeff-461d-8fe0-a542718f7211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81ae6e00-0273-45f2-a2ee-781dcd497733",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros((1, 2, 12 * 16**2, 1))\n",
    "N = test.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "716d2fe3-8d47-484d-8b6c-018b83a9013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = win.window_partition(test, (2, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8497961d-8f14-41c4-b959-d82eb1107957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([239, 32, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf7c6dff-6d37-4c2c-adbe-c37c1fb57f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "colors = np.arange(windows.shape[0])\n",
    "#np.random.shuffle(colors)\n",
    "for idx in range(windows.shape[0]):\n",
    "    windows[idx, :, :] = 0 #float(colors[idx])\n",
    "windows[100, :, :] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7fe2d25-a2ba-4c5a-9f0e-22f742bcbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_debug = win.window_reverse(windows, (2, 16), 2, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e7f60-815d-414d-b3ce-73f8024fbf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19ccd889-4680-40d0-b010-aafb46f3a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter = shift.RingShift(nside=16, base_pix=12, window_size=(2, 16), shift_size=2*16, input_resolution=(2, N))\n",
    "shifted = shifter.shift(window_debug)\n",
    "\n",
    "windows = win.window_partition(shifted, (2, 16))\n",
    "windows[100, :, :] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0576a4-486e-462e-a07e-75ed09b2214d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1395554-3096-41cb-aa80-d1718db139a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 3072])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_debug = win.window_reverse(windows, (2, 16), 2, N)\n",
    "window_debug = window_debug.permute(0, 1, 3, 2)\n",
    "window_debug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d1642ee-4fb7-4d1f-be76-2a5ebeb0b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] Connection to localhost:5431\n",
      "[db] Uploading artifact\n",
      "[db] Chunk 1\n",
      "[Database] Added artifact isolatitude_window_small.npy: artifacts/results/ring_windows_git_3d77aed_config_e4a5d1d/isolatitude_window_small.npy.npy\n"
     ]
    }
   ],
   "source": [
    "save_and_register(f\"isolatitude_window_small.npy\", window_debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1505931-3747-4042-ad8b-41c4b9f2ea1f",
   "metadata": {},
   "source": [
    "# Equivariance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9fd63099-3d36-4ae4-8769-5645c247cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments.weather.models.swin_hp_pangu as swinhppangu\n",
    "import experiments.weather.models.swin_hp_pangu_isolatitude as swinhppangu_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa8908-e85c-4aef-b8ba-eae8f17efec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
