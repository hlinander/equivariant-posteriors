import dask
print("dask module loaded from:", dask.__file__)
print("dask version:", dask.__version__)
import sys
print(sys.path)


# requires to install eofs and gpytorch
import xarray as xr
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
#import gpytorch
import os
import glob
#from eofs.xarray import Eof

from torch.utils.data import DataLoader
from torch.utils.data import Dataset

from typing import Dict, Optional, List, Callable, Tuple, Union

#import wandb
#from sklearn.model_selection import train_test_split, cross_val_score
#from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt


import healpix
def interpolate_dh_to_hp(nside, variable: xr.DataArray):
    """
    Input is xr.DataArray 
    """
    
    npix = healpix.nside2npix(nside)
    hlong, hlat = healpix.pix2ang(nside, np.arange(0, npix, 1), lonlat=True, nest=True)
    hlong = np.mod(hlong, 360)
    xlong = xr.DataArray(hlong, dims="z")
    xlat = xr.DataArray(hlat, dims="z")

    xhp = variable.interp(lat=xlat, lon=xlong, kwargs={"fill_value": None})
    hp_image = np.array(xhp.to_numpy(), dtype=np.float32) # ! removed to_array()
    return hp_image

def interpolate_dh_to_hp_output(nside, variable: xr.DataArray):
    """
    Input is xr.DataArray 
    """
    
    npix = healpix.nside2npix(nside)
    hlong, hlat = healpix.pix2ang(nside, np.arange(0, npix, 1), lonlat=True, nest=True)
    hlong = np.mod(hlong, 360)
    xlong = xr.DataArray(hlong, dims="z")
    xlat = xr.DataArray(hlat, dims="z")

    xhp = variable.interp(y=xlat, x=xlong, kwargs={"fill_value": None})
    hp_image = np.array(xhp.to_numpy(), dtype=np.float32) # ! removed to_array()
    return hp_image

def e5_to_numpy_hp(e5xr, nside: int, normalized: bool):
    """
    Input is class with xr.DataArray class variables
    """

    hp_surface = interpolate_dh_to_hp(nside, e5xr.surface)
    hp_upper = interpolate_dh_to_hp(nside, e5xr.upper)

    if normalized:
        stats = deserialize_dataset_statistics(nside)
        hp_surface, hp_upper = normalize_sample(stats.item(), hp_surface, hp_upper)

    return hp_surface, hp_upper


def structure_data(ds, num_steps_to_plot):
    """
    
    """

    for item in ds.data_vars:
        print(item)

    #num_steps_to_plot = 1
    for timestep in range(num_steps_to_plot):
        #print(timestep)
        plot_gas_and_timestep(ds, timestep)
    
    arr = ds.to_array().values  # shape (variable, lat, lon) or (... depends on dataset)
    print(arr.shape)
    # If there is still a leading dim for 'variable', move to flatten consistently:
    #arr = np.asarray(arr)
    #return arr.ravel()
    return None


def first_nc_under(dirpath: str) -> str:
    """Return the first .nc file found under dirpath (recursive). Raises if none."""
    files = glob.glob(os.path.join(datapath, "**", "*.nc"), recursive=True)
    if not files:
        raise FileNotFoundError(f"No .nc files under: {dirpath}")
    return files[0]


from dataclasses import dataclass

@dataclass
class ClimsetInputSample:
    BC: xr.Dataset
    CH4: xr.Dataset
    CO2: xr.Dataset
    SO2: xr.Dataset


def get_output_data(path: str, mode: str):
    nc_files = []
    
    if mode == 'train':
        experiments = train_experiments
    elif mode == 'test':
        experiments = test_experiments
        
    for mod in models:

        model_dir = os.path.join(path, mod)
        ensembles = os.listdir(model_dir)

        if total_ensembles == 1:
            ensembles = ensembles[0]
        
        exp_counter = 0
        for exp in experiments:
            for var in variables:
                var_dir = os.path.join(path, mod, ensembles, exp, var, '250_km/mon')
                files = glob.glob(var_dir + '/**/*.nc', recursive=True)
                nc_files += files
        
            if exp_counter == 0:
                dataset = xr.open_mfdataset(nc_files).compute().to_array().to_numpy()
        
            else: #concatenate dataset in time dimension
                other_experiment = xr.open_mfdataset(nc_files).compute().to_array().to_numpy()
                dataset = np.concatenate((dataset, other_experiment), axis=1)
                
                
            exp_counter += 1
            
        dataset = np.moveaxis(dataset, 0, 1)
        print(dataset.shape)
        dataset = dataset.reshape(dataset.shape[0], -1)
        
        # TODO: remove next line, only used for making quick tests
        dataset = dataset[:, :1]
    
    return dataset


from tqdm import tqdm
datapath = "/proj/heal_pangu/users/x_tagty/climateset"
input_dir = os.path.join(datapath, "inputs", "input4mips")
target_dir = os.path.join(datapath, "outputs", "CMIP6")

fire_type = 'all-fires'
variables = ['tas']
models = ['CAS-ESM2-0']
train_experiments = ["ssp585", "ssp126", "ssp370"] 
test_experiments = ["ssp245"]
input_gases = ['BC_sum', 'CH4_sum', 'CO2_sum', 'SO2_sum']
print("got here")

exp = train_experiments[0]
gas_datasets = []

BC = []
CH4 = []
CO2 = []
SO2 = []
for idx, gas in tqdm(enumerate(input_gases)):
    var_dir = os.path.join(input_dir, exp, gas, '250_km', 'mon')
    files = glob.glob(var_dir + '/**/*.nc', recursive=True)

    for f in files:
        if gas == 'BC_sum' and fire_type in f:
            BC.append(f)
    for f in files:
        if gas == 'CH4_sum' and fire_type in f:
            CH4.append(f)
    for f in files:
        if gas == 'SO2_sum' and fire_type in f:
            SO2.append(f)
    for f in files:
        if gas == 'CO2_sum':
            CO2.append(f)

print(len(BC))
print(len(CH4))
print(len(SO2))
print(len(CO2))


import sys
print(sys.executable)

import netCDF4
print(netCDF4.__file__)
print(netCDF4.__version__)

import xarray as xr
print(xr.backends.list_engines())


gas_dict = {'BC': BC, 
            'CH4': CH4,
            'SO2': SO2, 
            'CO2': CO2
           }

timestep = 1
data_timestep = []
for key, gas_data in gas_dict.items():
    print("gas_data[0] =", gas_data[0], type(gas_data[0]))
    with xr.open_dataset(gas_data[0]) as ds:
        print(ds)
        data_grid = ds[key].isel(time=timestep)
        data_timestep.append(data_grid)


test_sample = ClimsetInputSample(
    BC = data_timestep[0],
    CH4 = data_timestep[1],
    SO2 = data_timestep[2],
    CO2 = data_timestep[3])

nside = 32
BC_hp = interpolate_dh_to_hp(nside, test_sample.BC)
CH4_hp = interpolate_dh_to_hp(nside, test_sample.CH4)
SO2_hp = interpolate_dh_to_hp(nside, test_sample.SO2)
CO2_hp = interpolate_dh_to_hp(nside, test_sample.CO2)


import healpy
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm

def healpix_plotting(hp_data, data_shift=0, norm=None, nest=True):
    data = hp_data + data_shift
    healpy.visufunc.cartview(data, nest=nest, norm=norm)
    healpy.visufunc.orthview(data, nest=nest, norm=norm)
    healpy.visufunc.mollview(data, nest=nest, norm=norm)
    healpy.visufunc.gnomview(data, nest=nest, norm=norm)



# plt.hist(BC.values.flatten(), bins=200)
# plt.yscale('log')
# plt.show()

lon_min, lon_max = -180, 180
lat_min, lat_max = -90, 90
extent = [lon_min, lon_max, lat_min, lat_max]

plt.imshow(test_sample.BC, #extent=extent,
           origin='lower')
plt.show()

shift = 1e-16
plt.imshow(test_sample.BC + shift, norm=LogNorm(), #extent=extent, 
           origin='lower')
plt.show()

print(BC_hp.size)





test_sample.BC



healpix_plotting(BC_hp)
#healpix_plotting(BC_hp, shift, norm=LogNorm())





#healpix_plotting(CH4_hp)
healpix_plotting(CH4_hp, shift, norm=LogNorm())





#healpix_plotting(SO2_hp)
healpix_plotting(SO2_hp, shift, norm=LogNorm())





#healpix_plotting(CO2_hp)
print(CO2_hp.min())
shift = 5e-10
healpix_plotting(CO2_hp, shift, norm=LogNorm())





# Han
#for exp in experiments:
mod = 'CAS-ESM2-0'
ensembles = 'r3i1p1f1'
nc_files = []
for var in variables:
    var_dir = os.path.join(target_dir, mod, ensembles, exp, var, '250_km', 'mon')
    files = glob.glob(var_dir + '/**/*.nc', recursive=True)
    nc_files += files



ds = xr.open_mfdataset(nc_files, concat_dim="time", combine="nested")
ds = ds.sortby("time")


ds


ds['tas']


data_grid = ds['tas'].isel(time=timestep)
output_hp = interpolate_dh_to_hp_output(nside, data_grid)
healpix_plotting(output_hp)


# CH4_ds = xr.open_dataset(CH4[0])
# SO2_ds = xr.open_dataset(SO2[0])
# CO2_ds = xr.open_dataset(CO2[0])

.data_vars)
# timestep = 1

# data_grid = ds[var_name].isel(time=timestep)

# for var in var_names:
#     xr.open_dataset(BC[0])


# #
# keys = ds.attrs.keys()
# # for key in keys:
# #     print(f'{key}:    {ds.attrs[key]} \n')

# print(ds.attrs['dataset_category'])
# print(ds.attrs['data_structure'])
# print(ds.attrs['data_usage_tips'])

# num_steps_to_plot = 1
# arr = structure_data(ds, num_steps_to_plot)
